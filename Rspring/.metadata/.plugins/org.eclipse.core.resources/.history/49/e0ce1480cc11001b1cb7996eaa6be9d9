package com.spring.controller;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FSDataInputStream;
import org.apache.hadoop.fs.FSDataOutputStream;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.stereotype.Controller;
import org.springframework.ui.Model;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RequestMethod;

@Controller
public class HomeController {
	
	private static final Logger logger = LoggerFactory.getLogger(HomeController.class);
	FileSystem fs = null;
	
	@RequestMapping(value = "/", method = RequestMethod.GET)
	public String home(Model model) {
		return "home";
	}
	
	@RequestMapping(value = "/file", method = RequestMethod.GET)
	public String file(Model model) throws Exception {
		Configuration conf = new Configuration();
		conf.set("fs.defaultFS", "hdfs://localhost:9000");
		fs = FileSystem.get(conf);
		
		String srcPath = "c:/test/word.txt";
		String dstPath = "/store/test/";
		
		Path src = new Path(srcPath);
		Path dst = new Path(dstPath);
		
		if(!fs.exists(dst)) {
			fs.mkdirs(dst);
		}
		
		fs.copyFromLocalFile(src, dst);
		fs.close();
		
		String page = "http://localhost:9870/explorer.html#/store/test";
		model.addAttribute("page", page);
		
		return "home";
	}
	
	@RequestMapping(value = "/read", method = RequestMethod.GET)
	public String read(Model model) throws Exception {
		Configuration conf = new Configuration();
		conf.set("fs.defaultFS", "hdfs://localhost:9000");
		fs = FileSystem.get(conf);
		
		String srcPath = "c:/test/word.txt";
		Path src = new Path(srcPath);
		
		byte[] arr = new byte[1024];
		
		return "home";
	}
	
	@RequestMapping(value = "/delete", method = RequestMethod.GET)
	public String delete(Model model) {
		return "home";
	}
}
